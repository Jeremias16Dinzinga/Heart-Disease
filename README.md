# ğŸ§  RELATÃ“RIO DE PRÃ‰-PROCESSAMENTO â€“ DATASET HEART DISEASE

**Disciplina:** Aprendizagem AutomÃ¡tica I  
**Trabalho Escolar**

**Nome:** Jeremias Dinzinga  
**NÂº:** 1710393  
**Curso:** CiÃªncia de Dados e InteligÃªncia Artificial  
**Ano:** 2Âº

---

## ğŸ“‹ Tarefas Executadas

- Adicionei o ficheiro **â€œprocessed.cleveland.dataâ€** do dataset *Cleveland* (renomeado para **Cleveland.data**).  
- Salvei os dados num ficheiro CSV (**Cleveland.csv**) com **14 colunas**.  
- Verifiquei que **nÃ£o hÃ¡ dados duplicados**.  
- Analisei as informaÃ§Ãµes do dataset (**14 colunas e 302 registos vÃ¡lidos**).  
- Criei **histogramas** para cada variÃ¡vel e melhorei a exibiÃ§Ã£o para mostrar **4 por vez**.  
- Adicionei uma **funÃ§Ã£o** para controlar quantas variÃ¡veis sÃ£o exibidas por vez nos histogramas.  
- Mostrei a **distribuiÃ§Ã£o das classes** usando a variÃ¡vel `target` (presenÃ§a ou ausÃªncia de doenÃ§a cardÃ­aca).  
- Criei uma funÃ§Ã£o para **detectar outliers** com base no **1Âº e 3Âº quartil (IQR)**.  
- Visualizei a **proporÃ§Ã£o das classes (targets)**.  
- Analisei a **correlaÃ§Ã£o entre as variÃ¡veis** e tambÃ©m a correlaÃ§Ã£o individual de cada variÃ¡vel com o `target`.  
- Criei uma funÃ§Ã£o para **remover outliers**, caso seja necessÃ¡rio futuramente.  
- Como muitos valores foram identificados como *outliers* (mas clinicamente plausÃ­veis), **optei por nÃ£o removÃª-los** para evitar perda de informaÃ§Ãµes importantes.  
- Adotei uma **abordagem robusta de normalizaÃ§Ã£o**, reduzindo o impacto dos outliers sem eliminar dados vÃ¡lidos.  
- **Dividi o dataset em treino e teste.**  
- Gereii **versÃµes normalizadas** para treino e teste usando o **RobustScaler**, que utiliza a **mediana** e o **intervalo interquartil (IQR)** para escalar as variÃ¡veis contÃ­nuas.  

---

ğŸ“Œ **Resumo:**  
Este trabalho teve como objetivo preparar o *dataset Heart Disease (Cleveland)* para anÃ¡lises e modelagem preditiva, aplicando tÃ©cnicas de exploraÃ§Ã£o, detecÃ§Ã£o de outliers e normalizaÃ§Ã£o robusta, de forma a garantir a integridade e qualidade dos dados.
